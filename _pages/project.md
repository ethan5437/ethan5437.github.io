---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---

<div style="float:left">
<img src="/images/PR_VIST_overview.png" align="left" width="200px" height="200px" >
</div>
<div style="margin:8px;float:left;width:75%;text-align:justify;line-height:18px">
<b>Visual Storytelling Research #1</b>
<small><br>
<i>Like human writers, would machines generate better story if they learn to <q>plot</q> and <q>rework</q>? How do machines mimic such story writing techinques?</i>
<br>
<br>
Writing a coherent and engaging story is not easy. Creative writers use their knowledge andworldview to put disjointed elements together to form a coherent storyline, and work andrework iteratively toward perfection. We introduce PR-VIST, a framework that represents the input image se-quence as a story graph in which it finds thebest path to form a storyline. PR-VIST then takes this path and learns to generate the final story via a re-evaluating training process. 
<br> <a href="https://arxiv.org/pdf/2105.06950.pdf">[PAPER]</a></small>
</div>
<div style="clear:both"></div>
<hr> 

<div style="float:left">
<img src="/images/stretch_vist_1.png" align="left" width="200px" height="200px" >
</div>
<div style="margin:8px;float:left;width:75%;text-align:justify;line-height:18px">
<b>Visual Storytelling Demo Research </b>
<small><br>
<i>With a training data that only contain five-sentence stories, how do we prolong the stories? </i>
<br>
<br>
Distilled nouns and verbs from a sequence of images and utilized knowledge graph to find the important relations between nouns. 
Dynamically performed recurrent Transformer to generated stories with diverse length. 
The human evaluation showed that our model can generate longer stories, even when the input images are incohert.
<br> <a href="https://doraemon.iis.sinica.edu.tw/acldemo/index.html">[DEMO]</a> <a href="https://youtu.be/-uF8IV6T1NU">[VIDEO]</a></small>
</div>
<div style="clear:both"></div>
<hr> 

<div style="float:left">
<img src="/images/covid_sentiment_analysis.png" align="left" width="200px" height="200px" >
</div>
<div style="margin:8px;float:left;width:75%;text-align:justify;line-height:18px">
<b> COVID-19 X Essential Workers</b>
<small><br>
<i> How do we assess essential workers' mental well-being?</i>
<br>
<br>
The Covid-19 pandemic has led to large-scale lifestyle changes andincreased social isolation and stress on a societal level. This hashad a unique impact on US “essential workers” (EWs). We examine the use of Twitter by EWs as a step toward understanding the pandemic’simpact on their mental well-being, as compared to the populationas a whole. 
<br> <a href="/files/CHI_LBW_2021__1column.pdf">[PAPER]</a></small>
</div>
<div style="clear:both"></div>
<hr> 

<div style="float:left">
<img src="/images/deepdial_vist_overview.png" align="left" width="200px" height="200px" >
</div>
<div style="margin:8px;float:left;width:75%;text-align:justify;line-height:18px">
<b> Visual Question Generation</b>
<small><br>
<i> Lacking of visual question dataset for multiple images, how do machine generate questions?</i>
<br>
<br>
An engaging and provocative question can open up a great conversation. In this work, we explore a novel scenario: a conversation agent views a set of the user’s photos (for ex-ample, from social media platforms) and asks an engaging question to initiate a conversation with the user.
<br> <a href="/files/2021-deep-dial.pdf">[PAPER]</a></small>
</div>
<div style="clear:both"></div>
<hr> 



<div style="float:left">
<img src="/images/kgstory.png" align="left" width="200px" height="200px" >
</div>
<div style="margin:8px;float:left;width:75%;text-align:justify;line-height:18px">
<b>Visual Storytelling Research #2</b>
<small><br>
<i> End-to-end Models are limited to the vocabulary and knowledge in a single training dataset, how do we take advantage of external Knowledge Graphs to produce interesting stories? </i>
<br>
<br>
KG-Story, a three-stage framework that allows the story generation model to take advantage of external Knowledge Graphs to produce interesting stories. 
KG-Story distills a set of representative words from the input prompts, enriches the word set by using ex-ternal knowledge graphs, and finally generates stories based on the enriched word set. 
<br> 
<a href="https://arxiv.org/abs/1912.01496">[PAPER]</a></small>
</div>
<div style="clear:both"></div>
<hr> 


<div style="float:left">
<img src="/images/emoji.png" align="left" width="200px" height="200px" >
</div>
<div style="margin:8px;float:left;width:75%;text-align:justify;line-height:18px">
<b>Emoji Prediction</b>
<small>
<br>
Hashtags and Application Sources like Android, etc. 
are two features which we found to be important yet underused in emoji prediction and Twitter sentiment analysis on the whole. 
We showcase the importance of using Twitter features to helpthe model understand the sentiment involved and hence to predict the most suitable emoji for the text.
To further understand emoji behavioral patterns, we propose a more balanced dataset by crawling additional Twitter data,
including timestamp, hashtags, and application source acting as additional attributes to the tweet. 
<br> [Class Project] </small>
</div>
<div style="clear:both"></div>
<hr> 

<div style="float:left">
<img src="/images/Farmer_ML.jpg" align="left" width="200px" height="200px" >
</div>
<div style="margin:8px;float:left;width:75%;text-align:justify;line-height:18px">
<b>Predicting Crop Price Trends using a Deep Learning Approach</b>
<small>
<br>
Farmer suicides have become an urgent social problem that governments around the world are trying hard to solve. 
Most farmers are driven to suicide due to an inability to sell their produce at desired profit levels, which is caused by the widespread uncertainty/fluctuation in produce prices resulting from varying market conditions. 
To help the farmers with the issue of produce price uncertainty, this paper proposes a deep learning algorithm for prediction of future produce price trends (Increase, Decrease, Stable) based on past pricing and volume pattern.
<br> 
<a href="https://underline.io/events/24/sessions/464/lecture/2209-ameliorating-farmer-suicides-by-predicting-crop-price-trends-using-a-deep-learning-approach">[PAPER]</a></small>
</div>
<div style="clear:both"></div>
<hr> 


<div style="float:left">
<img src="/images/disaster.jpg" align="left" width="200px" height="200px" >
</div>
<div style="margin:8px;float:left;width:75%;text-align:justify;line-height:18px">
<b>Automatic Caption Generation for Twitter Disaster Scene</b>
<small>
<br>
Twitter is a mainstream social media platform for users to share information. Inparticular, during the disaster, there are large volume of tweets posted on Twitter withvarious kinds of contents. Fortunately, Twitter provides api that allows users to crawlthe images and captions from their database. Based on the given data, we proposed an image captioning model to generate textual descriptions for disaster-related images. 
<br> [Class Project] </small>
</div>
<div style="clear:both"></div>
<hr> 
